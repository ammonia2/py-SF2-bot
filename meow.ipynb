{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4d667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a782296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenateData():\n",
    "    \"\"\"Merge all character data in a single DataFrame & filter required cols\"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    dataDirectory = 'training_data_p2/'\n",
    "\n",
    "    # Defining expected dtypes for each column\n",
    "    dtype_dict = {\n",
    "        \"frame\": int,\n",
    "        \"p1Id\": int,\n",
    "        \"p1Health\": int,\n",
    "        \"p1PosX\": int,\n",
    "        \"p1PosY\": int,\n",
    "        \"p1Jump\": int,\n",
    "        \"p1Crouch\": int,\n",
    "        \"p1InMove\": int,\n",
    "        \"p1MoveId\": int,\n",
    "        \"p1Up\": int,\n",
    "        \"p1Down\": int,\n",
    "        \"p1Left\": int,\n",
    "        \"p1Right\": int,\n",
    "        \"p1Select\": int,\n",
    "        \"p1Start\": int,\n",
    "        \"p1Y\": int,\n",
    "        \"p1B\": int,\n",
    "        \"p1X\": int,\n",
    "        \"p1A\": int,\n",
    "        \"p1L\": int,\n",
    "        \"p1R\": int,\n",
    "        \"p2Id\": int,\n",
    "        \"p2Health\": int,\n",
    "        \"p2PosX\": int,\n",
    "        \"p2PosY\": int,\n",
    "        \"p2Jump\": int,\n",
    "        \"p2Crouch\": int,\n",
    "        \"p2InMove\": int,\n",
    "        \"p2MoveId\": int,\n",
    "        \"p2Up\": int,\n",
    "        \"p2Down\": int,\n",
    "        \"p2Left\": int,\n",
    "        \"p2Right\": int,\n",
    "        \"p2Select\": int,\n",
    "        \"p2Start\": int,\n",
    "        \"p2Y\": int,\n",
    "        \"p2B\": int,\n",
    "        \"p2X\": int,\n",
    "        \"p2A\": int,\n",
    "        \"p2L\": int,\n",
    "        \"p2R\": int,\n",
    "        \"timer\": int,\n",
    "        \"roundStarted\": int,\n",
    "        \"roundOver\": int,\n",
    "        \"fightResult\": str\n",
    "    }\n",
    "\n",
    "    column_names = [\n",
    "        \"frame\", \"p1Id\", \"p1Health\", \"p1PosX\", \"p1PosY\", \"p1Jump\", \"p1Crouch\", \"p1InMove\", \"p1MoveId\",\n",
    "        \"p1Up\", \"p1Down\", \"p1Left\", \"p1Right\", \"p1Select\", \"p1Start\", \"p1Y\", \"p1B\", \"p1X\", \"p1A\", \"p1L\", \"p1R\",\n",
    "        \"p2Id\", \"p2Health\", \"p2PosX\", \"p2PosY\", \"p2Jump\", \"p2Crouch\", \"p2InMove\", \"p2MoveId\",\n",
    "        \"p2Up\", \"p2Down\", \"p2Left\", \"p2Right\", \"p2Select\", \"p2Start\", \"p2Y\", \"p2B\", \"p2X\", \"p2A\", \"p2L\", \"p2R\",\n",
    "        \"timer\", \"roundStarted\", \"roundOver\", \"fightResult\"\n",
    "    ]\n",
    "\n",
    "    for filename in os.listdir(dataDirectory):\n",
    "        filepath = os.path.join(dataDirectory, filename)\n",
    "        df = pd.read_csv(filepath, low_memory=False, dtype=dtype_dict, skiprows=1, names=column_names)\n",
    "        data = pd.concat([data, df], ignore_index=True)\n",
    "\n",
    "    data = data[data['roundStarted'] != False]\n",
    "\n",
    "    # dropping cuz not needed\n",
    "    data = data.drop(['frame', 'roundStarted', 'fightResult', 'roundOver'], axis=1)\n",
    "\n",
    "    data['xDist'] = data['p1PosX'] - data['p2PosX']\n",
    "    data['yDist'] = data['p1PosY'] - data['p2PosY']\n",
    "    data = data.drop(columns=['p1PosX', 'p1PosY', 'p2PosX', 'p2PosY'], axis=1)\n",
    "    # print(data.dtypes)\n",
    "    # print(data.sample(5))\n",
    "    return data\n",
    "\n",
    "def normaliseFeatures(data):\n",
    "    \"\"\"Normalise yDist, xDist, health & timer values\"\"\"\n",
    "    # using StandardScalar here because it has advantages > standard max val normalisation\n",
    "    scaler = StandardScaler()\n",
    "    featuresToNormalise = ['p1Health', 'p2Health', 'timer', 'xDist', 'yDist']\n",
    "    data[featuresToNormalise] = scaler.fit_transform(data[featuresToNormalise])\n",
    "\n",
    "    # saving the scaler for later use\n",
    "    joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec294b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "        \"frame\", \"p1Id\", \"p1Health\", \"p1PosX\", \"p1PosY\", \"p1Jump\", \"p1Crouch\", \"p1InMove\", \"p1MoveId\",\n",
    "        \"p1Up\", \"p1Down\", \"p1Left\", \"p1Right\", \"p1Select\", \"p1Start\", \"p1Y\", \"p1B\", \"p1X\", \"p1A\", \"p1L\", \"p1R\",\n",
    "        \"p2Id\", \"p2Health\", \"p2PosX\", \"p2PosY\", \"p2Jump\", \"p2Crouch\", \"p2InMove\", \"p2MoveId\",\n",
    "        \"p2Up\", \"p2Down\", \"p2Left\", \"p2Right\", \"p2Select\", \"p2Start\", \"p2Y\", \"p2B\", \"p2X\", \"p2A\", \"p2L\", \"p2R\",\n",
    "        \"timer\", \"roundStarted\", \"roundOver\", \"fightResult\"\n",
    "    ]\n",
    "dtype_dict = {\n",
    "        \"frame\": int,\n",
    "        \"p1Id\": int,\n",
    "        \"p1Health\": int,\n",
    "        \"p1PosX\": int,\n",
    "        \"p1PosY\": int,\n",
    "        \"p1Jump\": int,\n",
    "        \"p1Crouch\": int,\n",
    "        \"p1InMove\": int,\n",
    "        \"p1MoveId\": int,\n",
    "        \"p1Up\": int,\n",
    "        \"p1Down\": int,\n",
    "        \"p1Left\": int,\n",
    "        \"p1Right\": int,\n",
    "        \"p1Select\": int,\n",
    "        \"p1Start\": int,\n",
    "        \"p1Y\": int,\n",
    "        \"p1B\": int,\n",
    "        \"p1X\": int,\n",
    "        \"p1A\": int,\n",
    "        \"p1L\": int,\n",
    "        \"p1R\": int,\n",
    "        \"p2Id\": int,\n",
    "        \"p2Health\": int,\n",
    "        \"p2PosX\": int,\n",
    "        \"p2PosY\": int,\n",
    "        \"p2Jump\": int,\n",
    "        \"p2Crouch\": int,\n",
    "        \"p2InMove\": int,\n",
    "        \"p2MoveId\": int,\n",
    "        \"p2Up\": int,\n",
    "        \"p2Down\": int,\n",
    "        \"p2Left\": int,\n",
    "        \"p2Right\": int,\n",
    "        \"p2Select\": int,\n",
    "        \"p2Start\": int,\n",
    "        \"p2Y\": int,\n",
    "        \"p2B\": int,\n",
    "        \"p2X\": int,\n",
    "        \"p2A\": int,\n",
    "        \"p2L\": int,\n",
    "        \"p2R\": int,\n",
    "        \"timer\": int,\n",
    "        \"roundStarted\": int,\n",
    "        \"roundOver\": int,\n",
    "        \"fightResult\": str\n",
    "    }\n",
    "\n",
    "df = pd.read_csv('training_data_p2/Balrog', low_memory=False, dtype=dtype_dict, skiprows=1, names=column_names)\n",
    "df.to_excel('output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = concatenateData()\n",
    "data = normaliseFeatures(data)\n",
    "data.to_excel('output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a55d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     p1Up  p1Down  p1Left  p1Right  p1Y  p1B  p1X  p1A  p2Up  p2Down  p2Left  \\\n",
      "0       0       0       0        0    0    0    0    0     0       0       0   \n",
      "1       0       0       0        0    0    0    0    0     0       0       0   \n",
      "2       0       0       0        0    0    0    0    0     0       0       0   \n",
      "272     0       0       1        0    0    0    0    0     0       0       0   \n",
      "273     0       0       1        0    0    0    0    0     0       0       0   \n",
      "\n",
      "     p2Right  p2Y  p2B  p2X  p2A  \n",
      "0          0    0    0    0    0  \n",
      "1          0    0    0    0    0  \n",
      "2          0    0    0    0    0  \n",
      "272        0    0    0    0    0  \n",
      "273        0    0    0    0    0  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['p1PosX', 'p1PosY'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m p1_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1Up\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1Down\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1Left\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1Right\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1Y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1B\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1X\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1A\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1PosX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1PosY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m p2_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2Up\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2Down\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2Left\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2Right\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2Y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2B\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2X\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2A\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2PosX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2PosY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 18\u001b[0m p1_counts \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp1_keys\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     19\u001b[0m p2_counts \u001b[38;5;241m=\u001b[39m filtered_data[p2_keys]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP1 counts:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Abdullah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Abdullah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abdullah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['p1PosX', 'p1PosY'] not in index\""
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = concatenateData()\n",
    "data = normaliseFeatures(data)\n",
    "\n",
    "# Filter movement and attack keys for p1 and p2\n",
    "movement_attack_keys = ['p1Up', 'p1Down', 'p1Left', 'p1Right', 'p1Y', 'p1B', 'p1X', 'p1A', \n",
    "                        'p2Up', 'p2Down', 'p2Left', 'p2Right', 'p2Y', 'p2B', 'p2X', 'p2A']\n",
    "\n",
    "filtered_data = data[movement_attack_keys]\n",
    "filtered_data = filtered_data[(filtered_data == 1).any(axis=1)]\n",
    "print(data[movement_attack_keys].head())\n",
    "# Plot the data\n",
    "p1_keys = ['p1Up', 'p1Down', 'p1Left', 'p1Right', 'p1Y', 'p1B', 'p1X', 'p1A', 'p1PosX', 'p1PosY']\n",
    "p2_keys = ['p2Up', 'p2Down', 'p2Left', 'p2Right', 'p2Y', 'p2B', 'p2X', 'p2A', 'p2PosX', 'p2PosY']\n",
    "\n",
    "p1_counts = filtered_data[p1_keys].sum()\n",
    "p2_counts = filtered_data[p2_keys].sum()\n",
    "print(\"P1 counts:\")\n",
    "print(p1_counts)\n",
    "\n",
    "print(\"P2 counts:\")\n",
    "print(p2_counts)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(p1_keys, p1_counts, label='Player 1', alpha=0.7)\n",
    "plt.bar(p2_keys, p2_counts, label='Player 2', alpha=0.7)\n",
    "plt.xlabel('Keys')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Player 1 vs Player 2 Movement and Attack Keys (Values = 1)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
